\lecture{1}{Sun 06 Sep 2022 12:20}{Examples of Hidden Markov Models}

\subsection{Приклад: середньорічна температура у минулому}
\begin{example}
Хотіли б визначити середню річну темепратуру в деякій області Землі, достатньо далекого минулого,
про яку немає ніяких метеорологічних записів. Потрібно знайти якісь опосередковані методи. Для
спрощенні будемо вважати що річна температура може бути просто високою або низькою.

Temperature: $T$ (warm year),  $X$ (cold year).

Введемо $\{X_k\}_{k \leq 0}$ зі множиною станів $E = \left\{ T, X \right\}$ де
$X_k$ температурна \\ характеристика $k$-го року.
\[
P \left( X_{k+1} = T  \mid X_k = T \right) = 0.7
.\] 
\[
P \left( X_{k+1} = X  \mid X_k = X \right) = 0.6
.\] 

Введемо матрицю перехідних ймовірностей із рядками та стовпцями, що\\
відповідають $T$ та $X$ температурним режимам.
\[
\begin{array}{rcl}
 \color{blue}\begin{array}{c} T \quad\; X \end{array}\\
  A =
  \color{blue}\begin{matrix} T \\ X \\ \end{matrix}
  \color{black}
  \begin{pmatrix}0,7&0,3\\0,4&0,6\\\end{pmatrix}&\hspace{-1em}  
\end{array}
.\]

Імовірність переходу з теплого у теплий $0.7$. З теплого у холодний  $0.3$.

Перехід схожий з умовою марковості: перехід залежит лише від температури попереднього року
для температури тепершнього.


Ми шукаємо якісь опосередковані способи поміряти темепратуру. Якісь
сучасні дослідження показують, що є певна кореляція між шириною кілець на спилах дерев
і темепратурою якв спостерігалась у тей чи інший рік.

Тепер ми маємо спостережуваний об'єкт, а температура попередніх років не була такою.
Нехай кільця на спилах дерев такі: $M$ малі, $C$ середні, $B$ - великі.

\[
B = \begin{pmatrix}
  0.1 & 0.4 & 0.5 \\
  0.7 & 0.2 & 0.1
\end{pmatrix}
.\] 

Нехай у теплий рік ми спостерігали мале кільце з імовірністю $0.1$, середнє імовірністю
 $0.4$ та велике з $0.5$.

Відповідно із таблицею і для холодного року.

Матриця $B$ це інформація про зв'язок мід $Y_k$ - розмір кільця в $k$-тий рік і
$X_k$ - температурою.

\[
  B_{ij} = P \left( Y_k = j  \mid X_k - i \right),
  \qquad j \in \left\{ M,C,B \right\} \; i \in \left\{ T, X \right\} 
.\]

Щоб виправдати слово "приховані" ми кажемо, що\\
$\left\{ X_k \right\}_{k\leq 0}$ прихована послідовність;

$\left\{ Y_k \right\}_{k \leq 0}$ спостережувана.

Припустимо, що ми цікавимо конкретним чотирирічним періодом,\\
що $Y = \left( M, C, M, B \right)$ - наші спостереження.

За $Y$ хочемо визначити найбільш ймовірну послідовність $X = \left( X_0, X_1, X_2, X_3 \right)$.

Це є класична задача прихованих марківських моделей: за певною послідовністю випадкових величин визначити
імовірну послідовність, яка відповідає певному прихованому процесу, з яким наші спостереження пов'язані у
відомий нам спосіб.

Для того, щоб далі нам продовжити нам потрібно зробити ще одне припущення, що ми знаємо, чи може зробили
якісь припущення про апріорний розподіл.
Ввадаємо, що нам відомо, чи так було стосовно певних спостережень, що відомі такі ймовірності:
\[
P \left( X_0 = T  \right) = 0.6; \quad P \left( X_0 = X \right) = 0.4
.\] 

Таку модель позначають ще $\lambda = \left( \mu, A, B \right) $ - позначення прихованої марківської
моделі.

\textbf{Як би ми могли розв'язувати таку задачу?}

Розлянемо скінченновимірні розподіли $X_k$ та $Y_k $ : $\left\{ \left( X_k, Y_k \right)  \right\}$ 

% \begin{gather*}
%   P_{\lambda} \left( X_0 = x_0, X_1 = x_1, \ldots, X_n = x_n, Y_0 = y_0, \ldots, Y_n = y_n \right) = \\
%   
% \end{gather*}

\begin{DispWithArrows*}[wrap-lines]
P_{\lambda} & = \left( X_0 = x_0, \ldots, X_n = x_n, Y_0 = y_0, \ldots, Y_n = y_n \right) =\\
% \Arrow{$\scriptscriptstyle P(A\cdot B) = P(A) \cdot P(B \mid A)$} \\
            &= P_{\lambda} \left( X_0 = x_0, \ldots, X_n = x_n \right) \cdot
            P_{\lambda} \left( Y_0 = y_0, \ldots, Y_n = y_n  \mid
            \vec{X} = \left( x_0, \ldots, x_1 \right)  \right) 
\end{DispWithArrows*}

Обчислюємо

\begin{gather*}
P_{\lambda} \left( X_0 = x_0, \ldots, X_n = x_n \right) = P_{\lambda} \left( X_0 = x_0 \right) 
\cdot P_{\lambda} \left( X_1 = x_1 \mid X_0 = x_0 \right) \cdot \\
P \left( X_2 = x_2 \mid X_1 = x_1, X_0 = x_0 \right) \cdot \ldots \cdot \\
P \left( X_n = x_n \mid X_{n-1} = x_{n-1}, \ldots, X_0 = x_0 \right) =
\end{gather*}

Марков міркував, що в умові не потрібні такі довгі лянцюжки іксів.

Ми припускаємо цю ланцюг марківський.

\begin{gather*}
= P_{\lambda} \left( X_0 = x_0 \right) \cdot P_{\lambda} \left( X_1 = x_1  \mid X_0 = x_0 \right)
\cdot P\left( X_2= x_2  \mid X_1 = x_1 \right) \cdot \ldots \cdot \\
\cdot P(X_n = x_n  \mid X_{n-1} = x_{n-1}) = \\
= \mu_{x_0} \cdot A_{x_0 x_1} \cdot A_{x_1 x_2} \cdot \ldots \cdot A_{x_{n-1}x_n}
\end{gather*}

Вважаємо, що випадкові величини $Y_0, .., Y_n$ є умовно незалежними при відомих
$X_0,\ldots, X_n$

\begin{gather*}
P_{\lambda} \left( Y_0 = y_0, \ldots, Y_n = y_n  \mid X_0  \right) \cdot
P_{\lambda} \left( Y_1 = y_0  \mid X_1 = x_1 \right) \cdot \ldots \cdot \\
P_{\lambda} \left( Y_n = y_n \mid X_n = x_n \right) = \\
= B_{x_0 y_0} \cdot B_{x_1 y_1} \cdot \ldots \cdot B_{x_n y_n}
\end{gather*}

Таким чином
\begin{gather*}
P_{\lambda} \left( X-0 = x_0, \ldots, X_n = x_n, Y_0 = y_0, \ldots, Y_n = y_n \right) = \\
= \underbrace{\mu_{x_0}}_{P\left( X_0 = x_0 \right) }
\cdot B_{x_0 y_0} \cdot A_{x_0 x_1} \cdot A_{x_1 x_2} \cdot B_{x_2 y_2} \cdot
\ldots \cdot A_{x_{n-1} x_n} \cdot B_{x_n y_n}
\end{gather*}

На прикладі:
\begin{gather*}
P_{\lambda} \left( X = \left( TTXX \right), Y = \left( MCMB \right) \right) =
0.6 \cdot 0.1 \cdot 0.7 \cdot 0.4 \cdot 0.3 \cdot 0.7 \cdot 0.6 \cdot 0.1
\end{gather*}

\begin{align*}
  &P_{\lambda} \left( X = \left( TTTT \right), Y = \left( MCMB \right) \right) = \\
  &= 0.6 \cdot 0.1 \cdot 0.7 \cdot 0.4 \cdot 0.7 \cdot 0.1 \cdot 0.7 \cdot 0.5 = 0.000412
.\end{align*}

$XXXT$ найбільш ймовірна послідовність.

Нас може цікавити:

$P_{\lambda} \left( X_0 = T, Y = \left( MCMB \right)  \right) =\\
= \sum_{x_1, x_2, x_3}^{} P_{\lambda}\left( X_0 = T, X_1 = x_1, X_2 = x_2, X_3 = x_3,
  Y = \left( MCMB \right) \right) = 0.1887 $

\[
P_{\lambda}\left( X_0 = X, Y = \left( MCMB \right) \right) = 1 - 0.1887 = 0.81183
\]

$P_{\lambda}\left( X_1 = T, Y = \left( MCMB \right) \right) = \\
=\sum_{x_0, x_2, x_3}^{} P_{\lambda}\left( X_0 = x_0, X_1 = T, X_2 = x_2, X_3 = x_3 \right)
= 0.519 > 0.5;$

більш ймовірно, що рік був теплим

$P_{\lambda}\left( X_2 = T, Y = y \right) = 0.228 < 0.5 \Rightarrow X_2 = X$ більш ймовірно

$P_{\lambda}\left( X_3 = T, Y = y \right) = 0.804 > 0.5 \Rightarrow X_3 = T$ більш ймовірно

$XTXT$ - послідовність на основі "індивідуальних" ймовірностей

\textbf{Обчислимо ймовірность ланцюжка $Y = \left( MCMB \right)$}

\begin{gather*}
P_{\lambda} \left( Y = \left( MCMB \right)  \right) = \sum_{x_0, x_1, x_2, x_3}^{}
P\left( X = \left( x_0, x_1, x_2, x_3 \right), Y = \left( MCMB \right) \right) = \\
= 0.009629
\end{gather*}

Ймовірність досить мала. Можливо, що модель може бути не адекватною, або ж
випадок є досить рідкістним.
Можливий і випадок, що ми помилилися із нашими апріорними припущеннями.
Так ми наблизилися до задачі навчання: пошуку моделі при якій ймовірність
випадку буде максимальною.
\end{example}

Прихована марківська модель це випадковий процес, який розділений на дві складові:
спостережувану та приховану.

% \begin{note}
%   Прихований стан ще називають латентний.
% \end{note}

Як приклад використання такого типу моделі можна взяти коливання цін на акції, де
прихований фактор може бути якимось економічним чи політничним. Змоделювати його
ми не ставимо за мету, але ми маємо його враховувати для того щоб краще змоделювати ціни
на акції.

\begin{example}[передача сигналу]
Наша задача найточніше відтворити сигнал.

$\left\{ B_k \right\}_{k \geq 0}$ - послідовність в.в. зі значеннями $0,1$;

 $Y_k$ - спостережений сигнал

  $Y_k$ співпадає з $B_k$ з ймовірністю $p$, спотворення з ймовірністю $1-p$ 

введемо $\left\{ \xi_k \right\}_{k\geq 0}$ - н.о.р., $\xi_k \sim B(p)$
тоді $X_k = B_k$ ;
\[
Y_k = \left( 1-\xi_k \right) \cdot X_k + \xi_k \cdot \left( 1 - X_k \right)
.\] 
Тут \[
A = \begin{pmatrix}
  1 - a & a \\
  a & 1 - a
\end{pmatrix} \qquad \mu = \left( 0.5; 0.5 \right) 
.\] 

\[
B = \begin{pmatrix}
  p & 1-p \\
  1-p & p
\end{pmatrix} 
.\] 

$\lambda = \left( \mu, A, B \right)$ - ПММ для каналу зв'язку
\end{example}

\begin{example}[фінансові часові ряди]
  Простіша модель часового ряду ринкової ціни акцій - Модель Блека-Шоуза.

  $S_k$ - ціна яку ми спостерігаємо у якийсь проміжок часу
\[ S_k = \exp\left\{\mu - \frac{\sigma^2}{2} + \sigma \cdot \xi_k \right\} \cdot S_{k-1} \]

де $\xi_k \sim \mathcal{N} (0,1)$ - н.о.р

$\sigma \in \R$ - волатильність - характеристика мінливості ціни

$\mu$ - норма прибутку

\[
  M \frac{S_k}{S_{k-1}} = e^{\mu - \sigma^2/2} \cdot \varphi_{\xi_{k}}\left( \frac{\sigma}{i} \right)
  = e ^{\mu}
.\] 

Така можель може досить добре працювати на коротких інтревалах.
На великих інтервалах ціни демонструють інші властивості, що не описуються цією моделлю.

Вводимо деякий випадковий процес $\left\{ X_k \right\}_{k \geq 0}$ який має приховані фактори

\[
S_k = \exp \left\{ \mu(X_k) - \sigma^2(X_k) / 2 + \sigma(X_k) \xi_k \right\} \cdot S_{k-1}
.\] 

$\mu$ та  $\sigma$ залежать від $\left\{ X_k \right\}_{k\geq 0}$

В цьому прикладі умовні ймовірності спостережуваного
$B_{xy} = P\left( Y_k = y  \mid X_k = x \right)$ замінюються на умовін щільності
\[
B_{xy} = P_{Y_k  \mid X_k}\left( y | x \right)
.\] 
Нехай $Y_k = \log \frac{S_k}{S_{k-1}} =
\mu(X_k) - \sigma^2(X_k) / 2 + \sigma(X_k) \xi_k$ і тоді при
$X_k = x$ отримаємо \[
  Y_k \sim \mathcal{N} \left( \mu(x) - \sigma^2(x) / 2; \sigma^2 (x) \right) 
.\] 

\end{example}
.
